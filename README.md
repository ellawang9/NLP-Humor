As human-AI interactions become increasingly commonplace, the ability for NLP models to authentically emulate human-like interactions becomes increasingly crucial. An important part of this capability is based on the model's capacity to decode and generate humor. In this work, we task state-of-the-art (SOTA) NLP models with two tasks: (1) matching a joke setup to its punchline, and (2) explaining why the joke is funny. These tasks, as presented in existing literature, assess an "understanding" of humor, whether it be identifying ironic scenarios or comprehending clever wordplay. We find that humans still significantly outperform language models in both tasks (BART for matching, GPTs for explanation). In addition to analyzing performance, we aim to understand if current models have the resolution to understand deep-rooted cultural difference in humor. Thus, we perform our analysis with two datasets of English and Chinese jokes and conduct quantitative and qualitative analyses between the two. Awareness of cultural nuances can enable future AI systems to engage in culturally sensitive conversations, improve cross-cultural communication, and foster cultural appreciation. This work illuminates the utility of such NLP models as human collaborators in tasks that not only require advanced semantic understanding, but also a sensible awareness of the cultural context.
